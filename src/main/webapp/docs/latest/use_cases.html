<!DOCTYPE html><html><head><meta charset="utf-8"><title>Untitled Document.md</title><style>

</style></head><body id="preview">
<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
“License”); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
  
    
<h1><a id="CarbonData_Use_Cases_0"></a>CarbonData Use Cases</h1>
<p>This tutorial discusses about the problems that CarbonData addresses. It shall take you through the identified top use cases of CarbonData.</p>
<h2><a id="Introduction_3"></a>Introduction</h2>
<p>For big data interactive analysis scenarios, many customers expect sub-second response to query TB-PB level data on general hardware clusters with just a few nodes.</p>
<p>In the current big data ecosystem, there are few columnar storage formats such as ORC and Parquet that are designed for SQL on Big Data. Apache Hive’s ORC format is
a columnar storage format with basic indexing capability. However, ORC cannot meet the sub-second query response expectation on TB level data, because ORC format
performs only stride level dictionary encoding and all analytical operations such as filtering and aggregation is done on the actual data. Apache Parquet is columnar
storage format that can improve performance in comparison to ORC because of its more efficient storage organization. Though Parquet can provide query response on TB level data in a
few seconds, it is still far from the sub-second expectation of interactive analysis users. Cloudera Kudu can effectively solve some query performance issues, but kudu
is not hadoop native, can’t seamlessly integrate historic HDFS data into new kudu system.</p>
<p>However, CarbonData uses specially engineered optimizations targeted to improve performance of analytical queries which can include filters, aggregation and distinct counts,
the required data needs to be stored in an indexed, well organized, read-optimized format, CarbonData’s query performance can achieve sub-second response.</p>
<h2><a id="Motivation_Single_Format_to_provide_low_latency_response_for_all_use_cases_16"></a>Motivation: Single Format to provide Low Latency Response for all Use Cases</h2>
<p>The main motivation behind CarbonData is to provide a single storage format for all the usecases of querying big data on Hadoop. Thus CarbonData is able to cover all use-cases
into a single storage format.</p>
<p><img src="images/format/carbon_data_motivation.png?raw=true" alt="Motivation"></p>
<ul>
<li>
<h3><a id="Sequential_Access_23"></a>Sequential Access</h3>
<ul>
<li>Supports queries that select only a few columns with a group by clause but do not contain any filters.<br>
This results in full scan over the complete store for the selected columns.</li>
</ul>
<p><img src="images/format/carbon_data_full_scan.png?raw=true" alt="Sequential_Scan"></p>
<p><strong>Scenario</strong></p>
<ul>
<li>ETL jobs</li>
<li>Log Analysis</li>
</ul>
</li>
<li>
<h3><a id="Random_Access_34"></a>Random Access</h3>
<ul>
<li>Supports Point Query. These are queries used from operational applications and usually select all or most of the columns but do involve a large number of filters which reduce the result to a small size. Such queries generally do not involve any aggregation or group by clause.
<ul>
<li>Row-key query(like HBase)</li>
<li>Narrow Scan</li>
<li>Requires second/sub-second level low latency</li>
</ul>
</li>
</ul>
<p><img src="images/format/carbon_data_random_scan.png?raw=true" alt="random_access"></p>
<p><strong>Scenario</strong></p>
<ul>
<li>Operational Query</li>
<li>User Profiling</li>
</ul>
</li>
<li>
<h3><a id="Olap_Style_Query_48"></a>Olap Style Query</h3>
<ul>
<li>Supports Interactive data analysis for any dimensions. These are queries which are typically fired from Interactive Analysis tools.<br>
Such queries often select a few columns but involve filters and group by on a column or a grouping expression.<br>
It also supports queries that :
<ul>
<li>Involves aggregation/join</li>
<li>Roll-up,Drill-down,Slicing and Dicing</li>
<li>Low-latency ad-hoc query</li>
</ul>
</li>
</ul>
<p><img src="images/format/carbon_data_olap_scan.png?raw=true" alt="Olap_style_query"></p>
<p><strong>Scenario</strong></p>
<ul>
<li>Dash-board reporting</li>
<li>Fraud &amp; Ad-hoc Analysis</li>
</ul>
</li>
</ul>

<script type="text/javascript">
 $('a[href*="#"]:not([href="#"])').click(function() {
   if (location.pathname.replace(/^\//, '') == this.pathname.replace(/^\//, '') && location.hostname == this.hostname) {
    var target = $(this.hash);
    target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
    if (target.length) 
        { $('html, body').animate({    scrollTop: target.offset().top - 52 },100);
          return false;
        }
     }
  });
</script>


</body></html>
